{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19eb6ef5-0762-4289-b8f9-4ffd8ca47ed4",
   "metadata": {},
   "source": [
    "# Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1c246332-cd36-4d63-9a4a-73d0ca41ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Como primer paso partimos de instalar las librerias necesarias para este proyecyto, las cuales aparecen a continuación:\n",
    "\n",
    "import esda \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import libpysal as lps\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a5ed3965-3ae6-41f4-8604-ac1e480797cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que genere los poligonos de la cdmx con la información que necesitamos, mediante un metodo constructor que genera \"objetos\" para este caso practico nuestro objeto son los poligonos, los cuales son formas geometricas que delimitan la forma que tienen las delegaciones. A estos obejetos les corresponde información contenida en la base de datos predial; es decir, a la información predial de Tlalpan (atributos) le asiganmos un poligono (objeto)  \n",
    "\n",
    "def csv2shp (df): #Definimos la función como \"csv2shp\"\n",
    "    pols=[] #creamos una lista vacia que almacenara los poligonos\n",
    "    for i in df.geo_shape: #Creamos un ciclo iterativo que genera la información de los poligonos que irán a la lista antes mencionada \n",
    "        pol=loads(i)['coordinates'][0] #Creamos una variable llamada \"pol\" que almacenara las coordenadas de los poligonos, esto es importante porque vuelve la información espacial. \n",
    "        if len(pol)<2: #Usamos if para el ciclo y quiere decir que en tanto se tengan menos de 2 poligonos se concretara el proceso de extraer las coordenadas para esa geometria   \n",
    "            pols.append(Polygon(pol[0])) #Polygon es un metodo constructor de la libreria \"shapely.geometry\"\n",
    "        else: #Else le indica al programa que hacer en caso de que se encuentre un multipoligono  \n",
    "            multis= [] #Es una lista vacia que almacenara aquellas geometrias que se compongan de poligonos compuestos de varias geometrias a lo cual llamamos multipoligono  \n",
    "            for j in pol: #ciclo para los multipoligonos \n",
    "                multis.append(Polygon(j)) #Implementa el metodo constructor en los multipoligonos \n",
    "            pols.append(MultiPolygon(multis)) #Añade los multipoligonos procesasdos a la lista de poligonos para tener nuestros datos completos \n",
    "\n",
    "    df['geometry']= pols #En la tabala que construimos llamada \"df\" almacenamos los datos procesados en el paso anterior  \n",
    "    gdf= gpd.GeoDataFrame(df,crs='EPSG:4326').drop(columns='geo_shape') #Creamos una variable llamada gdf que almacenará la proyección geografica asignada a los datos en la tabla df\n",
    "    \n",
    "    return gdf #Regresa los datos procesados en la forma deseada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ec6967c6-9e0b-4baa-91a9-00e3a9a07c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predio2ageb(cat,agebF):\n",
    "    cat['geometry']=cat.geometry.representative_point()\n",
    "    preRes=gpd.sjoin(agebF,cat).reset_index(drop=True).drop(columns=['index_right','fid','codigo_pos','colonia_pr','CVE_MUN'])\n",
    "    preRes=preRes.groupby('CVEGEO')[['superficie','anio_const','valor_unit']].mean().reset_index()\n",
    "    res= pd.merge(preRes, agebF[['CVEGEO','geometry']], on='CVEGEO')\n",
    "    res.crs = cat.crs\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6f028-6c10-493e-a639-15b1393fdc35",
   "metadata": {},
   "source": [
    "### Crear archivos shp con datos catastrles a nivel predio CDMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "db680cf7-09fa-4cee-a6d6-a19ae1ab888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para crear el mapa que nos muestre los valores prediales de la cdmx no contamos con datos que nos proporcione directamente esta información, pero podemos construir los datos a partir de dos conjuntos, uno que nos da la información espacial (geografica) y el otro nos da la base de datos de los valuos prediales.\n",
    "#Creamos una variable llamada csv para almacenar todos los archivos csv (contienen la información predial) esto debido a que se tiene un archivo csv por cada delegación\n",
    "csv= glob('Data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16701fa0-5fda-4b54-9da8-0a6bec1242ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▍                                                                        | 2/16 [01:50<12:19, 52.85s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(csv): #Creamos un ciclo para dar tratamiento a los datos en crudo, lo que se hizo fue extraer los datos que nos sirven para  el proyecto e  indicar el tipo de dato que es; es decir diferenciar entre los valores que son palabaras y  los que son números, es importante ya que así podremos realizar operaciones matematicas. \n",
    "    df= pd.read_csv(i, usecols= ['fid','codigo_postal','superficie_terreno','valor_unitario_suelo','geo_shape','colonia_predio','anio_construccion'],\n",
    "                    dtype= {'fid':str,'codigo_postal':str,'superficie_terreno':float,'valor_unitario_suelo':float,'geo_shape':str,'colonia_predio':str,'anio_construccion':float})\n",
    "\n",
    "    df= df[~df.geo_shape.isna()].copy() #Elimina aquellos datos que carecen de información espacial\n",
    "\n",
    "    gdf= csv2shp(df).to_crs('EPSG:32614') #Asignamos la proyección geografica correspondiente a la zona utm de la CDMX\n",
    "\n",
    "    gdf.to_file('Data/Outputs/{}.shp'.format(i[i.find('mx_')+3:i.find('_08')].replace(\" \",\"_\"))) #Indicamos que los resulados obetnidos deben almacenarce en un archivo llamado \"Outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c599689-a020-4b12-bafd-93304b22fa2c",
   "metadata": {},
   "source": [
    "### Juntar con archivos AGEB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6d8c2-bb3c-4c5d-bcfb-8a380bb805e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageb= gpd.read_file('Data/conjunto_de_datos/09a.shp')[['CVEGEO','geometry','CVE_MUN']] #Creamos una varibbale llamada ageb que almacenará los archivos shp de la ciudad de México, los cuales contienen la información que hace a nuestros datos espaciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eae60-fda8-4bfd-9295-d0a35608ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "agebR= gpd.read_file('Data/conjunto_de_datos/09ar.shp').to_crs('EPSG:32614')[['CVEGEO','geometry','CVE_MUN']] #Para un analisis completo consideraremos las zonas rurales de la CDMX de esta forma llevamos el analisis a todo el poligono que delimita el área de la CDMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852c26d-f312-43e1-a65e-6cc399fe30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageb.crs # Podemos  observar que los datos crudos se encuentran en un sistema de coordenadas conocido como \"CCL\" esto debido a que la información se produce así. Debemos pasarlo a un sistema conocido como UTM para poder realizar metricas estadisticas con los datos, así la información que se produzca será entendible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2193b-0113-4f0d-8a3a-f1c72bb6000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageb= ageb.to_crs('EPSG:32614') #Comando para reproyectar los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c766b3-8794-405b-8790-f39705af3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageb.crs #Podemos observar que los datos ya estan transformados y de esta forma podemos comenzar a hacer metricas estadisticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688ceeb-9e06-4191-80b9-589f7fd15ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageb= ageb.append(agebR).reset_index(drop=True) #Reestablecemoos el indice del cuadro de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4940dc-30d3-4c18-a788-f505d9e5aab5",
   "metadata": {},
   "source": [
    "### Filtramos información "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f80254-a61e-4b04-b4bb-1985247da19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cveMun= {'ALVARO_OBREGON':'010','AZCAPOTZALCO':'002','BENITO_JUAREZ':'014','COYOACAN':'003',\n",
    "         'CUAJIMALPA_DE_MORELOS':'004','CUAUHTEMOC':'015','GUSTAVO_A._MADERO':'005','IZTACALCO':'006',\n",
    "         'IZTAPALAPA':'007','MAGDALENA_CONTRERAS':'008','MIGUEL_HIDALGO':'016','MILPA_ALTA':'009',\n",
    "         'TLAHUAC':'011','TLALPAN':'012','VENUSTIANO_CARRANZA':'017','XOCHIMILCO':'013'}  #Creamos un diccionario de las alcaldias con su respectiva clave geoestadistica ya que esta será la que nos permitirá hacer el join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318539b-8e96-4aec-95f9-69b06c8f7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruts=glob('Data/Outputs/*.shp') #Creamos una variable llamada ruts que almacena los archivos shp de todas las alcaldias de la CDMX "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad74470-f7ae-4daa-8ef1-6b88b0e167aa",
   "metadata": {},
   "source": [
    "## Primeros resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887095b-0a37-4081-bf93-ba99854a9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ruts): #Creamos un cilco for para los archivos shp de las alcaldias\n",
    "    name=i[13:-4]\n",
    "    agebF=ageb[ageb.CVE_MUN==cveMun[name]] #Filtramos los ageb usando el diccionario del paso anterior y almacenamos los resultados en una variable llamada agebF\n",
    "    cat=gpd.read_file(i)\n",
    "    cat=cat[~((cat.valor_unit.isna()) | (cat.valor_unit==0))].copy() #Filtramos los valores prediales que no nos sirven, son aquellos que tienen un valor nulo o 0 \n",
    "    \n",
    "    res = predio2ageb(cat,agebF) #Creaomos una variable llamada res que almacena los ageb Filtrados y \"cat\" que almacena los archivos shp procesados \n",
    "    \n",
    "    res.plot(column='valor_unit',legend=True)\n",
    "    plt.title(name) \n",
    "    \n",
    "    res.to_file('Data/Outputs/CatastroAGEB/{}_cat.shp'.format(name)) #Mandamos todos los archivos obtenidos a una carpeta llamada outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5fc55-0839-41fd-9b1c-e5a6ee6cfd7d",
   "metadata": {},
   "source": [
    "#### Podemos observar que el resultado obtenido nos permite hacer algunas hipotesis ya que al hacer un analisis visual podemos ver que dentro de cada poligono que conforma al poligono de la alcaldia no se observan anomalias a simple vista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d796115-1977-4d26-8568-728f1b9a2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdmx= glob('Data/Outputs/CatastroAGEB/*.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afb645-d09c-4dfd-8e44-5ee30b73e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a0d7c-e16b-444e-a407-dd7f26f17808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ruts): #Creamos un cilco for para los archivos shp de las alcaldias\n",
    "    name=i[26:-4]\n",
    "    agebF1=ageb[ageb.CVE_MUN==cveMun[i]] #Filtramos los ageb usando el diccionario del paso anterior y almacenamos los resultados en una variable llamada agebF\n",
    "    cat1=gpd.read_file(i)\n",
    "    cat1=cat[~((cat.valor_unit.isna()) | (cat.valor_unit==0))].copy() #Filtramos los valores prediales que no nos sirven, son aquellos que tienen un valor nulo o 0 \n",
    "    \n",
    "    res1 = predio2ageb(cat1,agebF1) #Creaomos una variable llamada res que almacena los ageb Filtrados y \"cat\" que almacena los archivos shp procesados \n",
    "    \n",
    "    res.plot(column='valor_unit',legend=True)\n",
    "    plt.title(i) \n",
    "    \n",
    "    res.to_file('Data/Outputs/CatastroAGEB/{}_cat.shp'.format(i)) #Mandamos todos los archivos obtenidos a una carpeta llamada outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6f91d-d0e6-4929-b3c1-caf315196e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ruts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd7db5-cf9a-4aaf-a2cf-7aec50845c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a6f8c-85be-4f91-9ccc-fb9fff5e31ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
